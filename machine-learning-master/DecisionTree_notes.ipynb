{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "### Classification & Regression Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification of discrete categories. (E.g. Images, groups ... etc)\n",
    "Regression of continuous output variables (Age, credit score ..etc)\n",
    "\n",
    "* Classification Learning\n",
    "* Instances: **Input (vector of input values, features)**\n",
    "* Concept: **Function (maps input --> output)**\n",
    "* Target concept: (thing we are trying to answer Male/Female, Image class ) \n",
    "* Hypothesis class: **set of all concepts, all function we are willing to think about**\n",
    "* Sample: **Training Set**\n",
    "* Candidate concept: Candidate for either class\n",
    "* Testing Set : **Take Candidate concept and figure out if the candidate concept does the good job or not (Accuracy/Error testing)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Learning:  \n",
    "* Pick best attribute & split the data\n",
    "* Ask another question & split the data\n",
    "* Follow the answer path\n",
    "* Repeat until you get an answer \n",
    "\n",
    "Expressiveness\n",
    "* Represented by boolean function (e.g. AND function)\n",
    "\n",
    "ID3 (Top-down learning Algorithm) : \n",
    "* Assign A <- best attribute for a node (Information Gain)\n",
    "* For each value of A create descendent of node\n",
    "* Sort training examples to leaves\n",
    "* **IF** : Examples perfectly classified ***STOP !!***\n",
    "    * **ELSE** : ***START OVER LEAVES***\n",
    "    \n",
    "ID3 *Bias*\n",
    "* Restriction Bias\n",
    "* Preference Bias\n",
    "\n",
    "* **Inductive Bias**\n",
    "    * Good split near top\n",
    "    * Correct model to incorrect\n",
    "    * Shorter trees to longer\n",
    "    \n",
    "    \n",
    "*Question: Does it make sense to repeat an attribute in a tree?*\n",
    "* No for discrete value attribute.\n",
    "* For continuous value attribute, you can ask different question about the attribute.\n",
    "\n",
    "**Other considerations**\n",
    "* *Continuous variable might produce infinite leaves* \n",
    "    * split the values e.g 10<age<20\n",
    "* *When to Stop?*\n",
    "    * Ideally when correctly classified\n",
    "    * No more attributes to split\n",
    "    * No overfitting (Big, complex tree)\n",
    "    * Pruning\n",
    "* *Regression problem*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some more information\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Allows to ask linear and multiple linear questions\n",
    "* Follow codes and example in [scikit-learn](http://scikit-learn.org/stable/modules/tree.html#)\n",
    "* Some more parameters to choose from\n",
    "    * Criterion (e.g. Entropy)\n",
    "    * Maximum depth\n",
    "    * Minimum sample in split and minimum sample in leaf\n",
    "* Entopy (Measure of impurity) = sum<sub>(i)</sub>[(-p<sub>(i)</sub> log<sub>(2)</sub>p<sub>(i)</sub>]\n",
    "    * p<sub>i</sub> : fraction of examples in class i (0 (No split) --> 1 (Evenly Split))\n",
    "* Information Gain: Entropy(parent) - weighted_average[Entropy(children)]\n",
    "\n",
    "** *Decision Tree Maximizes the Information Gain * **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
